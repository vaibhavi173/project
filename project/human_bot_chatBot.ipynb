{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b48e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "data_path = \"human_text.txt\"\n",
    "data_path2 = \"robot_text.txt\"\n",
    "# Defining lines as a list of each line\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  lines = f.read().split('\\n')\n",
    "with open(data_path2, 'r', encoding='utf-8') as f:\n",
    "  lines2 = f.read().split('\\n')\n",
    "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
    "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
    "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
    "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
    "# Grouping lines by response pair\n",
    "pairs = list(zip(lines,lines2))\n",
    "#random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e12308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "for line in pairs[:400]:\n",
    "  input_doc, target_doc = line[0], line[1]\n",
    "  # Appending each input sentence to input_docs\n",
    "  input_docs.append(input_doc)\n",
    "  # Splitting words from punctuation  \n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  # Redefine target_doc below and append it to target_docs\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "  \n",
    "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
    "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    if token not in input_tokens:\n",
    "      input_tokens.add(token)\n",
    "  for token in target_doc.split():\n",
    "    if token not in target_tokens:\n",
    "      target_tokens.add(token)\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())\n",
    "\n",
    "\n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    \n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "        if timestep > 0:\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995054c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', 'hi there how are you'), ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'), ('how do you feel today tell me something about yourself', 'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'), ('how many virtual friends have you got', 'i have many but not enough to fully understand humans beings'), ('is that forbidden for you to tell the exact number', 'i ve talked with 143 users counting 7294 lines of text')]\n",
      "['hi', 'oh thanks i m fine this is an evening in my timezone', 'how do you feel today tell me something about yourself', 'how many virtual friends have you got', 'is that forbidden for you to tell the exact number']\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:5])\n",
    "print(input_docs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ede29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\hp\\anaconda3\\lib\\site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-22.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af9c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting six>=1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n",
      "scipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.0 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.23.0 which is incompatible.\n",
      "astroid 2.6.6 requires wrapt<1.13,>=1.11, but you have wrapt 1.14.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.47.0-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.23.0-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-62.6.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.8.0-py2.py3-none-any.whl (164 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, wheel, werkzeug, urllib3, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, rsa, pyparsing, pyasn1-modules, protobuf, oauthlib, numpy, idna, gast, charset-normalizer, certifi, cachetools, absl-py, requests, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.0.12 flatbuffers-1.12 gast-0.4.0 google-auth-2.8.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.47.0 h5py-3.7.0 idna-3.3 importlib-metadata-4.11.4 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 numpy-1.23.0 oauthlib-3.2.0 opt-einsum-3.3.0 packaging-21.3 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-2.28.0 requests-oauthlib-1.3.1 rsa-4.8 setuptools-62.6.0 six-1.16.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 typing-extensions-4.2.0 urllib3-1.26.9 werkzeug-2.1.2 wheel-0.37.1 wrapt-1.14.1 zipp-3.8.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow --ignore-installed --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d6e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "32/32 [==============================] - 18s 433ms/step - loss: 1.2405 - accuracy: 0.0224 - val_loss: 1.3503 - val_accuracy: 0.0200\n",
      "Epoch 2/60\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.1743 - accuracy: 0.0237 - val_loss: 1.3699 - val_accuracy: 0.0200\n",
      "Epoch 3/60\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1706 - accuracy: 0.0238 - val_loss: 1.3882 - val_accuracy: 0.0200\n",
      "Epoch 4/60\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 1.1708 - accuracy: 0.0239 - val_loss: 1.4120 - val_accuracy: 0.0200\n",
      "Epoch 5/60\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 1.1843 - accuracy: 0.0237 - val_loss: 1.4977 - val_accuracy: 0.0195\n",
      "Epoch 6/60\n",
      "32/32 [==============================] - 16s 506ms/step - loss: 1.2043 - accuracy: 0.0234 - val_loss: 1.4750 - val_accuracy: 0.0205\n",
      "Epoch 7/60\n",
      "32/32 [==============================] - 16s 493ms/step - loss: 1.1842 - accuracy: 0.0241 - val_loss: 1.4648 - val_accuracy: 0.0198\n",
      "Epoch 8/60\n",
      "32/32 [==============================] - 16s 497ms/step - loss: 1.1776 - accuracy: 0.0237 - val_loss: 1.4851 - val_accuracy: 0.0198\n",
      "Epoch 9/60\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 1.1790 - accuracy: 0.0239 - val_loss: 1.4968 - val_accuracy: 0.0195\n",
      "Epoch 10/60\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 1.1715 - accuracy: 0.0240 - val_loss: 1.5142 - val_accuracy: 0.0200\n",
      "Epoch 11/60\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 1.1691 - accuracy: 0.0242 - val_loss: 1.5373 - val_accuracy: 0.0205\n",
      "Epoch 12/60\n",
      "32/32 [==============================] - 20s 630ms/step - loss: 1.1691 - accuracy: 0.0243 - val_loss: 1.5443 - val_accuracy: 0.0200\n",
      "Epoch 13/60\n",
      "32/32 [==============================] - 21s 663ms/step - loss: 1.1654 - accuracy: 0.0243 - val_loss: 1.5643 - val_accuracy: 0.0200\n",
      "Epoch 14/60\n",
      "32/32 [==============================] - 16s 491ms/step - loss: 1.1646 - accuracy: 0.0244 - val_loss: 1.5750 - val_accuracy: 0.0205\n",
      "Epoch 15/60\n",
      "32/32 [==============================] - 16s 498ms/step - loss: 1.1681 - accuracy: 0.0237 - val_loss: 1.5938 - val_accuracy: 0.0200\n",
      "Epoch 16/60\n",
      "32/32 [==============================] - 17s 518ms/step - loss: 1.1661 - accuracy: 0.0239 - val_loss: 1.6039 - val_accuracy: 0.0198\n",
      "Epoch 17/60\n",
      "32/32 [==============================] - 14s 442ms/step - loss: 1.1649 - accuracy: 0.0243 - val_loss: 1.6154 - val_accuracy: 0.0200\n",
      "Epoch 18/60\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 1.1641 - accuracy: 0.0238 - val_loss: 1.6278 - val_accuracy: 0.0203\n",
      "Epoch 19/60\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 1.1622 - accuracy: 0.0240 - val_loss: 1.6365 - val_accuracy: 0.0200\n",
      "Epoch 20/60\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 1.1655 - accuracy: 0.0239 - val_loss: 1.6408 - val_accuracy: 0.0198\n",
      "Epoch 21/60\n",
      "32/32 [==============================] - 16s 499ms/step - loss: 1.1643 - accuracy: 0.0241 - val_loss: 1.6490 - val_accuracy: 0.0200\n",
      "Epoch 22/60\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 1.1655 - accuracy: 0.0240 - val_loss: 1.6500 - val_accuracy: 0.0200\n",
      "Epoch 23/60\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 1.1635 - accuracy: 0.0239 - val_loss: 1.6511 - val_accuracy: 0.0200\n",
      "Epoch 24/60\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 1.1613 - accuracy: 0.0239 - val_loss: 1.6618 - val_accuracy: 0.0200\n",
      "Epoch 25/60\n",
      "32/32 [==============================] - 15s 480ms/step - loss: 1.1637 - accuracy: 0.0239 - val_loss: 1.6579 - val_accuracy: 0.0200\n",
      "Epoch 26/60\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 1.1653 - accuracy: 0.0240 - val_loss: 1.6537 - val_accuracy: 0.0200\n",
      "Epoch 27/60\n",
      "32/32 [==============================] - 15s 485ms/step - loss: 1.1619 - accuracy: 0.0241 - val_loss: 1.6584 - val_accuracy: 0.0200\n",
      "Epoch 28/60\n",
      "32/32 [==============================] - 16s 494ms/step - loss: 1.1626 - accuracy: 0.0241 - val_loss: 1.6641 - val_accuracy: 0.0200\n",
      "Epoch 29/60\n",
      "32/32 [==============================] - 15s 469ms/step - loss: 1.1633 - accuracy: 0.0238 - val_loss: 1.6553 - val_accuracy: 0.0203\n",
      "Epoch 30/60\n",
      "32/32 [==============================] - 15s 472ms/step - loss: 1.1624 - accuracy: 0.0241 - val_loss: 1.6618 - val_accuracy: 0.0200\n",
      "Epoch 31/60\n",
      "32/32 [==============================] - 15s 474ms/step - loss: 1.1612 - accuracy: 0.0239 - val_loss: 1.6619 - val_accuracy: 0.0200\n",
      "Epoch 32/60\n",
      "32/32 [==============================] - 15s 476ms/step - loss: 1.1618 - accuracy: 0.0241 - val_loss: 1.6642 - val_accuracy: 0.0200\n",
      "Epoch 33/60\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 1.1628 - accuracy: 0.0239 - val_loss: 1.6519 - val_accuracy: 0.0200\n",
      "Epoch 34/60\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 1.1606 - accuracy: 0.0239 - val_loss: 1.6534 - val_accuracy: 0.0200\n",
      "Epoch 35/60\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 1.1791 - accuracy: 0.0240 - val_loss: 1.6488 - val_accuracy: 0.0200\n",
      "Epoch 36/60\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 1.1604 - accuracy: 0.0241 - val_loss: 1.6479 - val_accuracy: 0.0200\n",
      "Epoch 37/60\n",
      "32/32 [==============================] - 15s 460ms/step - loss: 1.1603 - accuracy: 0.0241 - val_loss: 1.6527 - val_accuracy: 0.0200\n",
      "Epoch 38/60\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.1596 - accuracy: 0.0241 - val_loss: 1.6563 - val_accuracy: 0.0198\n",
      "Epoch 39/60\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.1594 - accuracy: 0.0239 - val_loss: 1.6605 - val_accuracy: 0.0200\n",
      "Epoch 40/60\n",
      "32/32 [==============================] - 15s 459ms/step - loss: 1.1587 - accuracy: 0.0239 - val_loss: 1.6575 - val_accuracy: 0.0200\n",
      "Epoch 41/60\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 1.1586 - accuracy: 0.0243 - val_loss: 1.6587 - val_accuracy: 0.0198\n",
      "Epoch 42/60\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 1.1565 - accuracy: 0.0241 - val_loss: 1.6599 - val_accuracy: 0.0200\n",
      "Epoch 43/60\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 1.1564 - accuracy: 0.0243 - val_loss: 1.6631 - val_accuracy: 0.0198\n",
      "Epoch 44/60\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 1.1560 - accuracy: 0.0245 - val_loss: 1.6628 - val_accuracy: 0.0200\n",
      "Epoch 45/60\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 1.1555 - accuracy: 0.0240 - val_loss: 1.6633 - val_accuracy: 0.0200\n",
      "Epoch 46/60\n",
      "32/32 [==============================] - 15s 462ms/step - loss: 1.1537 - accuracy: 0.0246 - val_loss: 1.6624 - val_accuracy: 0.0200\n",
      "Epoch 47/60\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 1.1511 - accuracy: 0.0243 - val_loss: 1.6628 - val_accuracy: 0.0213\n",
      "Epoch 48/60\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 1.1556 - accuracy: 0.0241 - val_loss: 1.6643 - val_accuracy: 0.0200\n",
      "Epoch 49/60\n",
      "32/32 [==============================] - 13s 395ms/step - loss: 1.1523 - accuracy: 0.0247 - val_loss: 1.6595 - val_accuracy: 0.0200\n",
      "Epoch 50/60\n",
      "32/32 [==============================] - 15s 469ms/step - loss: 1.1586 - accuracy: 0.0241 - val_loss: 1.6403 - val_accuracy: 0.0195\n",
      "Epoch 51/60\n",
      "32/32 [==============================] - 14s 450ms/step - loss: 1.1529 - accuracy: 0.0244 - val_loss: 1.6508 - val_accuracy: 0.0198\n",
      "Epoch 52/60\n",
      "32/32 [==============================] - 16s 499ms/step - loss: 1.1510 - accuracy: 0.0246 - val_loss: 1.6569 - val_accuracy: 0.0200\n",
      "Epoch 53/60\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 1.1551 - accuracy: 0.0241 - val_loss: 1.6598 - val_accuracy: 0.0200\n",
      "Epoch 54/60\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 1.1526 - accuracy: 0.0246 - val_loss: 1.6589 - val_accuracy: 0.0200\n",
      "Epoch 55/60\n",
      "32/32 [==============================] - 15s 461ms/step - loss: 1.1505 - accuracy: 0.0244 - val_loss: 1.6637 - val_accuracy: 0.0210\n",
      "Epoch 56/60\n",
      "32/32 [==============================] - 15s 458ms/step - loss: 1.1471 - accuracy: 0.0249 - val_loss: 1.6649 - val_accuracy: 0.0205\n",
      "Epoch 57/60\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 1.1463 - accuracy: 0.0251 - val_loss: 1.6592 - val_accuracy: 0.0200\n",
      "Epoch 58/60\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 1.1492 - accuracy: 0.0249 - val_loss: 1.6640 - val_accuracy: 0.0205\n",
      "Epoch 59/60\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 1.1455 - accuracy: 0.0256 - val_loss: 1.6643 - val_accuracy: 0.0203\n",
      "Epoch 60/60\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 1.1447 - accuracy: 0.0258 - val_loss: 1.6736 - val_accuracy: 0.0200\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "#Dimensionality\n",
    "dimensionality = 256\n",
    "#The batch size and number of epochs\n",
    "batch_size = 10\n",
    "#epochs = 600\n",
    "epochs = 60\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#Model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "#Compiling\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "#Training\n",
    "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "training_model.save('training_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6521be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "training_model = load_model('training_model.h5')\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "def decode_response(test_input):\n",
    "    #Getting the output states to pass into the decoder\n",
    "    states_value = encoder_model.predict(test_input)\n",
    "    #Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    #Setting the first token of target sequence with the start token\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "    \n",
    "    #A variable to store our response word by word\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "          #Predicting output tokens with probabilities and states\n",
    "          output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "    #Choosing the one with highest probability\n",
    "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "          sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "          decoded_sentence += \" \" + sampled_token\n",
    "    #Stop if hit max length or found the stop token\n",
    "          if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "    #Update the target sequence\n",
    "          target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "          target_seq[0, 0, sampled_token_index] = 1.\n",
    "          #Update states\n",
    "          states_value = [hidden_state, cell_state]\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7939e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
      "hi\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " i i i i is i \n",
      "bye\n",
      "Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "class ChatBot:\n",
    "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "#Method to start the conversation\n",
    "  def start_chat(self):\n",
    "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
    "    \n",
    "    if user_response in self.negative_responses:\n",
    "      print(\"Ok, have a great day!\")\n",
    "      return\n",
    "    self.chat(user_response)\n",
    "#Method to handle the conversation\n",
    "  def chat(self, reply):\n",
    "    while not self.make_exit(reply):\n",
    "      reply = input(self.generate_response(reply)+\"\\n\")\n",
    "    \n",
    "  #Method to convert user input into a matrix\n",
    "  def string_to_matrix(self, user_input):\n",
    "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "    user_input_matrix = np.zeros(\n",
    "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
    "      dtype='float32')\n",
    "    for timestep, token in enumerate(tokens):\n",
    "      if token in input_features_dict:\n",
    "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "    return user_input_matrix\n",
    "  \n",
    "  #Method that will create a response using seq2seq model we built\n",
    "  def generate_response(self, user_input):\n",
    "    input_matrix = self.string_to_matrix(user_input)\n",
    "    chatbot_response = decode_response(input_matrix)\n",
    "    #Remove <START> and <END> tokens from chatbot_response\n",
    "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
    "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
    "    return chatbot_response\n",
    "#Method to check for exit commands\n",
    "  def make_exit(self, reply):\n",
    "    for exit_command in self.exit_commands:\n",
    "      if exit_command in reply:\n",
    "        print(\"Ok, have a great day!\")\n",
    "        return True\n",
    "    return False\n",
    "  \n",
    "chatbot = ChatBot()\n",
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f26871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
      "hi\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      " i i i i is i \n",
      "bye\n",
      "Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62bffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
